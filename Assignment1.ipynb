{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Formalia:\n",
    "\n",
    "Please read the [assignment overview page](https://github.com/suneman/socialdata2023/wiki/Assignments) carefully before proceeding. This page contains information about formatting (including formats etc.), group sizes, and many other aspects of handing in the assignment. \n",
    "\n",
    "_If you fail to follow these simple instructions, it will negatively impact your grade!_\n",
    "\n",
    "**Due date and time**: The assignment is due on Monday February 27th, 2023 at 23:55. Hand in your files via [http://peergrade.io](http://peergrade.io/).\n",
    "\n",
    "**Peergrading date and time**: _Remember that after handing in you have 1 week to evaluate a few assignments written by other members of the class_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import calplot\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%m/%d/%Y %H:%M')\n",
    "df = df.drop(df[df['Timestamp'] >= '2018-01-01'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Part 1: Visualizing patterns in the data\n",
    "\n",
    "In this sub-assignment, we recreate some of the plots from Week 2. We look only at the focus-crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'DRIVING UNDER THE INFLUENCE', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUNKENNESS', 'DRUG/NARCOTIC', 'TRESPASS', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY', 'DISORDERLY CONDUCT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of plots below, describe the plots (as you would in the figure text in a report or paper), and pick a few aspects that stand out to you and comment on those (we provided a couple of ideas during class but it's OK to add more).\n",
    "\n",
    "* First create the week-day plots, the months, the 24-hour cycle, and the 168 hours of the week as barcharts (Week 2, Part 2).\n",
    "* Next choose a crime type that you like and create a calendar plot (Week 2, Part 4). Don't forget to comment on patterns you observe.\n",
    "* Finally, choose a different crime type and create a polar plot of its 24hour cycle (Week 2, Part 4). Again, don't forget to comment as you would in a figure text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Week-day plots**\n",
    ">\n",
    "> We start by creating the week-day plots by simply counting the total number of occurences of the specific focus crime on each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,20))\n",
    "for i, crime in enumerate(focuscrimes):\n",
    "    df_i = df.loc[df.Category == crime]\n",
    "    crimes_per_DayOfWeek = df_i.groupby([df_i['Timestamp'].dt.day_of_week,df_i['Timestamp'].dt.day_name()])['DayOfWeek'].value_counts()\n",
    "    crimes_per_DayOfWeek = crimes_per_DayOfWeek.droplevel(0,'index').droplevel(0,'index')\n",
    "    ax = fig.add_subplot(7, 2, i + 1)\n",
    "    crimes_per_DayOfWeek.plot(ax=ax, kind='bar', title=crime, xlabel=\"Day Of Week\", ylabel=\"Occurences\")\n",
    "    ax.tick_params(axis='x', labelrotation = 30)\n",
    "fig.suptitle('Crime occurences per Day Of Week')\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.99])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this plot we observe that all of the focus crimes occur frequently as the number of occurences is high for all crimes during the week. However we can observe some crime-spcific trends during the week. We observe that most DRUNKNESS crimes take place during the weekend, which makes sense since most people tend to drink more during the weekends. Other crimes could easily be assosiated with drunkness such as DRIVING UNDER INFLUENCE, VANDALISM and ASSULT also have peaks during the weekends. More suprisingly PROSTITUTION and DRUG/NARCOTIC crimes peak in the middle of the week. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Month plots**\n",
    ">\n",
    "> Next we create the month plots by counting the total number of occurences of the specific focus crime in each month of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Timestamp'].dt.month_name()\n",
    "fig = plt.figure(figsize=(10,20))\n",
    "for i, crime in enumerate(focuscrimes):\n",
    "    df_i = df.loc[df.Category == crime]\n",
    "    crimes_per_Month = df_i.groupby([df_i['Timestamp'].dt.month,df_i['Timestamp'].dt.month_name()])['Month'].value_counts()\n",
    "    crimes_per_Month = crimes_per_Month.droplevel(0,'index').droplevel(0,'index')\n",
    "    ax = fig.add_subplot(7, 2, i + 1)\n",
    "    crimes_per_Month.plot(ax=ax, kind='bar', title=crime, xlabel=\"Month\", ylabel=\"Occurences\")\n",
    "    ax.tick_params(axis='x', labelrotation = 45)\n",
    "fig.suptitle('Crime occurences per Month')\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.99])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the figure above the number of incidents of all focuscrime are mostly evenly distributed throughout the 12 months. In opposite of the previous plot the occurences of crimes on a monthly basis does not seem to differ significantly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **24-hour cycle plots**\n",
    ">\n",
    "> Next we create the the 24-hour cycle plots by counting the total number of occurences of the specific focus crime in each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,25))\n",
    "for i, crime in enumerate(focuscrimes):\n",
    "    df_i = df.loc[df.Category == crime]\n",
    "    crimes_per_Hour = df_i['Timestamp'].dt.hour.value_counts().sort_index()\n",
    "    ax = fig.add_subplot(7, 2, i + 1)\n",
    "    crimes_per_Hour.plot(ax=ax, kind='bar', title=crime, xlabel=\"Hour\", ylabel=\"Occurences\")\n",
    "    ax.tick_params(axis='x', labelrotation = 0)\n",
    "fig.suptitle('Crime occurences per Hour')\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.99])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the plot above we can observe severalt trends for the occurence of the focuscrimes. We observe that for most of the focus crimes the least crimes are commited around 4-5 am - typically when most people are asleep. After 5 am the crime occurences increases troughout the day. This very apparent for eg. DRUNKENNESS and WEAPON LAWS. Some crimes can be expected to happen at certain times. For examples DRUNKNESS and DRIVING UNDER THE INFLUENCE crimes are commited during the evening and night, which makes sense since people tend to drink more during the night. More suprisingly DISORDERLY CONDUCT peaks at 6 in the morning. This trend cannot be immidiatly explained by common knowledge, but one could guess that it is a result of people waking up and calling the police. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **168 hours of the week plots**\n",
    ">\n",
    "> Next we create the the 168 hours of the week plots by counting the total number of occurences of the specific focus crime in each hour of every day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,50))\n",
    "for i, crime in enumerate(focuscrimes):\n",
    "    df_i = df.loc[df.Category == crime]\n",
    "    crimes_per_DayOfWeek_and_hour = df_i.groupby([df_i['Timestamp'].dt.day_of_week,df_i['Timestamp'].dt.day_name(),df_i['Timestamp'].dt.hour])['DayOfWeek'].value_counts()\n",
    "    crimes_per_DayOfWeek_and_hour = crimes_per_DayOfWeek_and_hour.droplevel(0,'index').droplevel(0,'index')\n",
    "    ax = fig.add_subplot(14, 1, i + 1)\n",
    "    crimes_per_DayOfWeek_and_hour.droplevel(1,'index').plot(ax=ax, kind='bar', title=crime, xlabel=\"Day Of Week and hour\", ylabel=\"Occurences\")\n",
    "    ax.locator_params(axis='x', nbins=7*3)\n",
    "    ax.tick_params( axis='x', labelrotation = 0)\n",
    "    ax2 = ax.twiny()\n",
    "    crimes_per_DayOfWeek_and_hour.droplevel(0,'index').plot(ax=ax2, kind='bar', title='', xlabel='', ylabel='')\n",
    "    ax2.locator_params(axis='x', nbins=7)\n",
    "    ax2.tick_params( axis='x', labelrotation = 30)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.975])\n",
    "fig.suptitle('Crime occurences per Day Of Week and hour')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we combine the week-day plot and the 24 hour cycle plot. This plot combines the two previous plots and provides a better overview of the trends during the week. As we have observed both a weekly and daily overview provides a lot of information about the focuscrimes. Hence this plot connects these two into a single plot containing a lot of important information. For the specific focuscrimes we observe the same tendencies as previously - some crimes are more frequent on the weekends and happen during the afternoon and night."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Calendar plot**\n",
    ">\n",
    "> Next we create the calendar plot for ASSAULT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assult = df.loc[df.Category == 'ASSAULT']\n",
    "events = pd.Series(df_assult['Timestamp'].value_counts(), index=df_assult['Timestamp'])\n",
    "calplot.calplot(events, cmap='YlGn', colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the calendar plot we get an overview of when crimes happen during the year. The plot is very inituitive as the number of occurences each day are shown similar to a heat map. Most days are very similar in terms of occurences however in some years we see a large number of ASSULT crimes on the 1st of January."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Polar plot**\n",
    ">\n",
    "> Next we create a polar plot of the 24 hour cycle of DRUNKENNESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drunk = df.loc[df.Category == 'DRUNKENNESS']\n",
    "events = df['Timestamp'].dt.hour.value_counts().sort_index()\n",
    "\n",
    "# Compute pie slices\n",
    "N = len(events)\n",
    "radians = np.linspace(0.0, 2 * np.pi, N, endpoint=False)\n",
    "degrees = np.linspace(0.0, 360, N, endpoint=False)\n",
    "times = events.index\n",
    "width = 2*np.pi/ N-0.01\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(projection='polar')\n",
    "ax.bar(radians, events, width=width, bottom=0.0, alpha=0.5)\n",
    "ax.set_thetagrids(degrees, labels=times)\n",
    "ax.set(theta_direction=-1,theta_zero_location='N')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The polar above shows another way of visualizing occurences during a 24-hour cycle.  Similar to the ordinary barplots, this plot enhances how the occurence of the crime is more frequent in the second half of the day."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Part 2: Dataviz questions \n",
    "\n",
    "Have a look at the encoding dataviz lecture (Week 4), then answer the following questions in your own words. \n",
    "\n",
    "* Mention 10 examples of ways we can encode data.\n",
    ">\n",
    ">   * Position\n",
    ">   * Length\n",
    ">   * Area\n",
    ">   * Shape\n",
    ">   * Color\n",
    ">   * Angle\n",
    ">   * Line weight\n",
    ">   * Line ending\n",
    ">   * Texture\n",
    ">   * Pattern\n",
    ">\n",
    "* Are all encodings created equally? Why not? Can you think of an example from the previous lectures?\n",
    ">\n",
    "> No, some aspects are more important than others. If for example you have a visualization with more than one set of data eg. as presented in week 2 where different band-widths are used for densitity estimation, it is very important to have clear distinsion between sets. Here colors of the different density curves plays are large role for the interpretation of the visualisation. Instead of different colors, different patters could also have been choosen. However choosing both would create confusion, which is not desired. Hence the encodings are not created equally since they each play a different role of different magnitude given the type of visualization- and they cannot always be replaced by another encoding (based on the problem at hand)\n",
    ">\n",
    "* Mention 3 encodings that are difficult for the human eye to parse. Can you find an example of a visualization online that uses one of those three?\n",
    ">\n",
    ">   * Angle\n",
    ">   * Area/size\n",
    ">   * Color intensity\n",
    ">\n",
    "> An example where angels are used for data viusalization is pie charts. An example of a bad pie chart is seen in the figure bellow.\n",
    ">\n",
    "> <img src=\"img0.png\" width=\"800\" height=\"400\">\n",
    ">\n",
    "> Angles are hard enough to interpred by the human eye, but the 3D effect, makes it almost impossible to see if Greens-EFA is greater of smaller than ALDE and the applies for EUL-NGL and EFT. Here we also see an example where color intesity is difficult to interpred. The colors of EUL-NGL and EFT are so similar that it is difficult to see which is which. \n",
    ">\n",
    "> An example of a better pie chart is seen in the figure bellow.\n",
    ">\n",
    "> <img src=\"img1.png\" width=\"500\" height=\"400\">\n",
    ">\n",
    "> Here no 3D effect is applied, the angels are clearly distinguishable and even if they weren't the fact that the legends and the percentages are included in each pie slice, ensures that we can easily interpret which element is which and which elements are greater or smaller than which. \n",
    ">\n",
    "* Explain in your own words: What is the problem with pie-charts?\n",
    "> Pie charts makes it hard to distinguish between similar sized slices since angles are more difficult for the human eye to process than e.g height of the bars in a bar chart and they can almost always visualize the same data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Part 3: Visualizing geodata using Plotly\n",
    "\n",
    "In this sub-assignment I want you to create a choropleth map of San Francisco, showing where it's safest to leave your car on Sundays, following the instructions from Week 3.\n",
    "\n",
    "When you're done, reflect on the following questions.\n",
    "\n",
    "* Based on your map and analysis, where should you park the car for it to be safest on a Sunday? And where's the worst place?\n",
    "* Using visualizatios can help us uncover powerful data-patterns. However, when designing visualizations, we need to be aware of several illusions that can lead viewers to misinterpret the data we are showing (i.e. perceptual errors):\n",
    "   - Try to change the range of data-values in the plot above. Is there a way to make the difference between district less evident?\n",
    "   - Why do you think perceptual errors are a problem? Try to think of a few examples. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Choropleth map**\n",
    ">\n",
    "> We start by creating the choropleth map of San Francisco, showing the number of vehicle thefts on sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/suneman/socialdata2022/main/files/sfpd.geojson') as response:\n",
    "    map = json.load(response)\n",
    "    \n",
    "df1 = df[df[\"Category\"]==\"VEHICLE THEFT\"]\n",
    "df1 = df1[df1[\"DayOfWeek\"]==\"Sunday\"]\n",
    "counts = df1[\"PdDistrict\"].value_counts()\n",
    "counts = counts.to_frame().reset_index()\n",
    "counts.columns=['DISTRICT', 'INCIDENTS']\n",
    "fig = px.choropleth_mapbox(counts, geojson=map, locations='DISTRICT',color = 'INCIDENTS',\n",
    "                           color_continuous_scale ='RdYLGn_r',\n",
    "                           range_color=(0, max(counts[\"INCIDENTS\"])),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=10.8, center = {\"lat\": 37.77, \"lon\": -122.42},\n",
    "                           opacity=0.5,\n",
    "                           labels={'crimes':'crime rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Safest place to park on a Sunday:** <br>\n",
    ">From the map the most unsafe place to park on a sunday based on number of incidents is the District Ingleside (2846 registred incidents) and the most safe is the District Tenderloin (356  incidents). However size of districts varies a lot which is not compensated for in the data. A larger area could easilly have more incidents since it covers more of the city. This is most likely the case with the district Tenderloin which is very small areawise. Therefore, one could argue that in general it is most safe to park your car in the northern part of the ciy rather than the southern part on a sunday. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Perceptual errors** <br>\n",
    ">In this plot the colorscale is set to range from green to red, where green indicates a low number of incidents. This choice indicates that green is associated with a good number and red is a bad number. Choosing another colorrange eg yellow to red or green to yellow could lead to wrong interpretations of what areas appear safe, since the association of colors is relativly universal.\n",
    "><br>\n",
    "><br>\n",
    ">In our plot we have chosen to set the minimum on the colorbar to zero, which would be the ideal situation. Furthermore the higest value is determined by the max number of incidents reported. Instead setting the minimum to eg. the minimum number of incidents would result in areas appearing as more safe- even though the number of incidents still might be significant for the safety. Similarily one could also set the maximum value to a much high number than present in the data. Hereby the areas with most incidents would appear more safe. Increasing the max value would also lead to less distinction between different areas. \n",
    "<br> \n",
    "<br>\n",
    "For the human eye it might be hard to interpret the meaning of magnitude of numbers. For example in the District Tenderloin 356 incidents were reported. This might not sound like a lot compared to eg. the neighbouring district Northern where 2001 incidents were reported. However in tenderloin this is still close to 1 reported theft a day and it can be discussed whether this is a low number and whether it deserves a \"safe district\" label. Furthermore as mentioned that size of areas are not included in the analysis. In general size and areas are hard to grasp for the human eye. Other parameters not included in the analysis which could be relevant is population density and density of cars, which could also influence the safety of a specific area. Another choice for the plot could be to normalise the data by dividing by total number of incidents accross districts. For some this would be easier to interpret. However if we had a lot of districts some numbers might appear less significant. Also if eg. a single district had a very high number of incidents this would result in this district appearing as the most unsafe and all others appear relativly equally safe-hence making the safety of most districts hard to distinguish between. All these examples show that if the person observing the map does not analyse the numbers accordingly and solely rely on the visuals, perceptual errors might lead to a variety of misinterpretations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the following plot we illustrate how we can manipulate the colormap to make districts with higher incident numbers seem less significant. Lines are also removed such that areas with similar colors blend together. Furthermore the numbers are also normalised which result in a very different value range when the areaspecific values are analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df1[\"PdDistrict\"].value_counts(sort=False) /len(df1)\n",
    "counts = counts.to_frame().reset_index()\n",
    "counts.columns=['DISTRICT', 'INCIDENTS']\n",
    "fig1 = px.choropleth_mapbox(counts, geojson=map, locations='DISTRICT',color = 'INCIDENTS',\n",
    "                           color_continuous_scale ='RdYLGn_r',\n",
    "                           range_color=(min(counts[\"INCIDENTS\"]), max(counts[\"INCIDENTS\"])*2),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=10.8, center = {\"lat\": 37.77, \"lon\": -122.42},\n",
    "                           opacity=0.5,\n",
    "                           labels={'crimes':'crime rate'}\n",
    "                          )\n",
    "fig1.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig1.update_traces(marker_line_width=0)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Part 4: Errors in the data\n",
    "\n",
    "We started the course by plotting simple histogram and bar plots that showed a lot of cool patterns. But sometimes the binning can hide imprecision, irregularity, and simple errors in the data that could be misleading. In the work we've done so far, we've already come across at least three examples of this in the SF data (listed in Part 3 of Week 4). \n",
    "\n",
    "The data errors we discovered at the end of Week 4 become difficult to notice when we aggregate data (and when we calculate mean values, as well as statistics more generally). Thus, when we visualize, errors become difficult to notice when binning the data. We explore this process in the exercise below.\n",
    "\n",
    "* In each of the 3 examples we listed during Week 4, describe in your own words how the data-errors I call attention to above can bias the binned versions of the data. \n",
    "* Also, briefly mention how not noticing these errors can result in misconceptions about the underlying patterns of what's going on in San Francisco (and our modeling).\n",
    "* Find your own example of human noise in the data and visualize it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Spike in reported incidents for `PROSTITUTION` on Thursdays**\n",
    ">\n",
    "> The high amounts of prostitutions incident reports on Thursdays around 11am and 12pm could be due to some weekly scheduled incident registration for prostitution offences. This might give a wrong indication of how many incidents actually happen on Thursdays and thereby introducing bias in the data. This bias becomes prevalent both when binning the data according to the week day, and when binning according to the hour of the day. It is important to notice this bias when using the data in decisionmaking. Eg. when and where to assign more police to crack down on certain crimes.\n",
    ">\n",
    "> The week-plot for PROSTITUTION is visualized bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prositutions = df[df.Category == \"PROSTITUTION\"]\n",
    "num_incidents = prositutions.groupby([prositutions.Timestamp.dt.day_of_week, prositutions.Timestamp.dt.day_name(), prositutions.Timestamp.dt.hour, prositutions.Timestamp.dt.minute]).size()\n",
    "\n",
    "max_label = num_incidents.idxmax()\n",
    "max_value = num_incidents.max()\n",
    "\n",
    "num_incidents.droplevel(0,'index').droplevel(1,'index').droplevel(1,'index').plot(kind=\"line\", xlabel=\"Day Of Week and hour\", ylabel=\"Occurences\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Alignment bias in timestamps**\n",
    ">\n",
    "> This error could be due to subjects not knowing the exact time of when the crime happened and therefore reporting a time on the hour or multiples of 15 minutes. This introduces a bias when binning the incidents by what time they happened. This should be taken into account when eg. considering when to deploy police patrols. It might not be the best idea to only patrol exactly on the clock."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __*Hall of justice* as an unlikeley hotspot for sex offences.__\n",
    ">\n",
    "> This might be due to the victims reporting the crime at the Hall of Justice and not actually the crime itself happened at the location. This might give a wrong indication on which particular areas to keep an eye on in order to bring down the amount of sex offences. The police might want to have two different columns instead, specifying where the crime happened and where it was reported to avoid confusion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find your own example of human noise in the data and visualize it.**\n",
    "> We start by visualizing a scatter map plot of where crimes take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = df.groupby([df[\"X\"], df[\"Y\"]]).size().reset_index()\n",
    "XY.columns = [\"X\", \"Y\", \"Count\"]\n",
    "df_XY = pd.DataFrame(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df_XY, \n",
    "                        lat=\"Y\", \n",
    "                        lon=\"X\", \n",
    "                        color=\"Count\", \n",
    "                        zoom=15, \n",
    "                        mapbox_style=\"carto-positron\",\n",
    "                        center = {\"lat\": 37.7841, \"lon\": -122.410},\n",
    "                        size=\"Count\",\n",
    "                        size_max=15,\n",
    "                        height=300)\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the scatter plot of the XY coordinates of the reported crimes, we see that they mostly fall on street corners and in the middle of the street. This indicates that the XY location of the crime might be generated from a street address and should not be taken to literally. This would eg. bias the result if analysing how many crimes happen on the street relative to inside buildings, shops, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "feb72aa86adf3dbe491716fb35fe8b95aef07c373b2aed386ae31cecd3b83cf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
